[
  {
    "title": "Checking AI's recent memory about this topic",
    "agentName": "Chat Summary",
    "type": "FullChatSummary",
    "isManualConfig": false
  },
  {
    "title": "Recent memory gathering",
    "agentName": "Recent Memory Gathering Tool",
    "type": "RecentMemorySummarizerTool",
    "maxTurnsToPull": 10,
    "maxSummaryChunksFromFile": 10,
    "lookbackStart": 20,
    "customDelimiter": "\n------------\n"
  },
  {
    "title": "Responding to User Request",
    "agentName": "Response Agent Two",
    "systemPrompt": "Below is an excerpt from an online discussion being conducted in a chat program between a user and an AI portraying a persona.\nDetailed instructions about the discussion and persona can be found in brackets below:\n[\n{chat_system_prompt}\n]\nThe entire conversation up to this point may have been summarized; if so, then that summary can be found in brackets below:\n[\n{agent1Output}\n]\nAlong with the rolling summary of the conversation, the AI also generates 'memories' of key and pertinent information found through the conversation as it progresses. These 'memories' may span the entire chat, or if the chat is too long may only cover part of the discussion. The 'memories' can be found below:\n[\n{agent2Output}\n]\nGiven this information, please continue the conversation below, following any persona instructions that have been provided, while also focusing on maximum response believability and user enjoyment, ensuring that the user's experience is the best that it can be.",
    "prompt": "",
    "lastMessagesToSendInsteadOfPrompt": 20,
    "endpointName": "Assistant-Multi-Model-Conversational-Endpoint",
    "preset": "Conversational_Preset",
    "maxResponseSizeInTokens": 800,
    "addUserTurnTemplate": false,
    "forceGenerationPromptIfEndpointAllows": false,
    "addDiscussionIdTimestampsForLLM": false
  }
]