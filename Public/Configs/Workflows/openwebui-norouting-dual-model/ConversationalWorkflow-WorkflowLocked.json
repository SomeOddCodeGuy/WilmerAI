[
  {
    "title": "Grab the current summary from file",
    "agentName": "Chat Summary File Puller Agent",
    "type": "GetCurrentSummaryFromFile"
  },
  {
    "title": "LLM Responding to User Request",
    "agentName": "Response Agent Four",
    "systemPrompt": "Below is an excerpt from an online discussion being conducted in a chat program between a user and an AI.\nDetailed instructions about the discussion can be found in brackets below:\n[\n{chat_system_prompt}\n]\nThe entire conversation up to this point may have been summarized; if so, then that summary can be found in brackets below:\n[\n{agent1Output}\n]\nGiven this information, please continue the conversation below.",
    "prompt": "",
    "lastMessagesToSendInsteadOfPrompt": 20,
    "endpointName": "OpenWebUI-NoRouting-Dual-Model-ResponderEndpoint",
    "preset": "_OpenWebUI_NoRouting_Dual_Model_Responder_Preset",
    "maxResponseSizeInTokens": 800,
    "addUserTurnTemplate": false,
    "returnToUser": true,
    "addDiscussionIdTimestampsForLLM": false
  },
  {
    "title": "Workflow Lock",
    "type": "WorkflowLock",
    "workflowLockId": "FullCustomChatSummaryLock"
  },
  {
    "title": "Checking AI's recent memory about this topic",
    "agentName": "Chat Summary",
    "type": "FullChatSummary",
    "isManualConfig": false
  }
]
