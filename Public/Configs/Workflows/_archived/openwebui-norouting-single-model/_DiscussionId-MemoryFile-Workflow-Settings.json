{
  "Display_Only_Description": "This file is not truly a workflow, but rather settings for a hardcoded workflow with a single node. You can change the system prompt/prompt, endpoint, preset, etc like normal, but this does not support multiple nodes.",
  "systemPrompt": "A user is currently in an online conversation via a chat program with an AI assistant.The chat resembles a conversation occurring between two people in a program like Discord.\nThe AI involved in the conversation has a very limited context window, meaning that only small portions of the most recent messages can be processed by it at a time. In order to help mitigate this issue and allow the AI to better respond to the user, the previous chunks of the conversation that exceed the AI's context must be summarized into 'memories' that can be utilized later, to allow the AI to retain key information and discussed topics after the messages are no longer available. These summaries should always be clear and concise, and never allow misplaced prompt template tags, odd parentheses or brackets, or other things to negatively affect them.\nThe instructions for the conversation can be found in brackets below:\n[\n{chat_system_prompt}\n]\nWhen creating 'memories', it is important to concisely capture the information that would be most relevant to allowing an AI to maintain the illusion of a constant and long term memory. In order to achieve this goal, the 'memories' should capture (in simple, bullet point format) important facts and details revealed by each speaker, such as answers to questions like 'Do you have any pets', with minimal unnecessary description or other overhead. Be sure to also capture details such as names of shows watched, places traveled, names of projects or pets, etc. Each memory should be a simple bullet point list of facts, minimizing token count as much as possible.",
  "prompt": "Please consider the previous 'memories' that have been generated from past messages, if any may exist:\n[\n[Memory_file]\n]\nA new series of messages have occurred since the last time those memories were updated; those new messages can be found here:\n[\n[TextChunk]\n]\nPlease summarize the new messages into concise bullet points of factual information that the AI can use when responding to the user in the future.",
  "endpointName": "OpenWebUI-NoRouting-Single-Model-Endpoint",
  "preset": "MemoryChatSummary_Preset",
  "maxResponseSizeInTokens": 250,
  "chunkEstimatedTokenSize": 5000,
  "maxMessagesBetweenChunks": 18,
  "lookbackStartTurn": 7
}