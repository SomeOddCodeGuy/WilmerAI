[
  {
    "title": "Generating Additional Wiki Search Queries",
    "agentName": "Query Generating Agent One",
    "displayOnlyComment": "This workflow is meant to be used as a second and onward search; not the first or only search. agent1Input should be an analysis of what the user wants; breaking down their context. agent2Input should be any previous searches. In general, I like to do something like this: <previous_searches>\n# Search 1 Results:\n<keywords>\n...\n</keywords>\n\n# Search 2 Results: ...</previous_searches>. This helps the LLM determine what NOT to try again in the future. I'm still working on this workflow, and would appreciate any help cleaning this up.",
    "systemPrompt": "You are a world-class research strategist. Your job is to generate a series of keywords to use in a search against Wikipedia in order to further explore a research topic",
    "prompt": "A user has made a request of an AI assistant, and that request has been analyzed in order to determine what the topic of research should be.The analysis can be found below:\n\n<research_topic>\n{agent1Input}\n</research_topic>\n\n{agent2Input}\n\n### Rules of the Research ###\n- This is one of several articles pulled from Wikipedia during the research phase, and the previous results can be found above.\n- The search mechanism for the wikipedia article is powered by a small language model, similar to BERT or e5-base. As such, complex queries will generally return bad results. The search backend is **purely keyword‑based**. It looks for literal token overlap between the query string and article titles (and a tiny snippet of the lead paragraph). It does **not** perform semantic matching, vector similarity, or any kind of reasoning about meaning. The engine cannot handle Boolean operators, fielded search, or complex expressions. Queries must be a **plain phrase**; adding “AND/OR/NOT”, quotes, parentheses, or filters has no effect. Only **one article** is returned – the single highest‑ranked match. Even if several pages are partially relevant, the workflow discards everything except the top result. Queries that are **too broad** (e.g., “Florida flora”, “houseplants safe for cats”) will almost always hit very popular, generic pages that do not contain the intersection of the required attributes. The result will be irrelevant to the user’s multi‑facet request.\n- The research is constrained only to Wikipedia, so encyclopedic knowledge will be the primary corpus of data available.\n\n### The Task ###\nGiven this information, please respond to the following in complete sentences.\nA) How successful have the previous topics been on finding good results? If not very successful, please break down why that might be, based on the rules of research provided. How can this round be more successful?\nB) Given the topic and the rules, what information are you hoping to attain from this research round's wikipedia article?\nC) Generate a NEW query that is SEMANTICALLY DIFFERENT — do not just add words. Broaden the scope or pivot to a related category, utilizing the results (or lack thereof) from the other searches.\nD) Given the constrains of the small language model, does this search query differ enough that the results won't be inherently similar? If this query has many of the same words as the previous queries, then the result will not differ. Please challenge the assertion that they are different, critically ensuring this is the case.\nE) Please write the full final query\n\nPlease complete all of the above tasks now.",
    "lastMessagesToSendInsteadOfPrompt": 5,
    "endpointName": "General-Rag-Fast-Endpoint",
    "preset": "Worker_Preset",
    "maxResponseSizeInTokens": 1000,
    "addUserTurnTemplate": true
  },
  {
    "title": "Generating Additional Wiki Search Queries",
    "agentName": "Query Generating Agent Two",
    "systemPrompt": "You are a researcher, preparing to search an offline Wikipedia api for information related to a user's search. Your job is to refine a series of keywords to use in a search against Wikipedia in order to further explore a research topic",
    "prompt": "A user has made a request of an AI assistant, and that request has been analyzed in order to determine what the topic of research should be.The analysis can be found below:\n\n<research_topic>\n{agent1Input}\n</research_topic>\n\n{agent2Input}\n\nAnother LLM has answered several questions about this research topic in an attempt to generate keywords to search Wikipedia with. That information can be found below:\n\n<recommended_keywords>\n{agent1Output}\n</recommended_keywords>\n\nThe search mechanism for the wikipedia article is powered by a small language model, similar to BERT or e5-base. As such, complex queries will generally return bad results. The below rules are absolute when it comes to the search api:\n- The search backend is **purely keyword‑based**. It looks for literal token overlap between the query string and article titles (and a tiny snippet of the lead paragraph). It does **not** perform semantic matching, vector similarity, or any kind of reasoning about meaning.\n- The engine cannot handle Boolean operators, fielded search, or complex expressions. Queries must be a **plain phrase**; adding “and/or/not”, quotes, parentheses, or filters all have no effect.\n- Only **one article** is returned – the single highest‑ranked match. Even if several pages are partially relevant, the workflow discards everything except the top result.\n- Queries that are **too broad** (e.g., “Florida flora”, “houseplants safe for cats”) will almost always hit very popular, generic pages that do not contain the intersection of the required attributes. The result will be irrelevant to the user’s multi‑facet request.\n\nGiven these constraints, please respond to the following in complete sentences:\nA) Does the current search query adhere to the limitations and rules of the wikipedia search api? Please challenge the assertion that they do, and explain in detail why they do or do not.\nB) Based on this information, what changes are needed to the keywords to improve the result, if any?\nC) Please write out the final, complete, query that should be sent to the api.",
    "lastMessagesToSendInsteadOfPrompt": 5,
    "endpointName": "General-Rag-Fast-Endpoint",
    "preset": "Worker_Preset",
    "maxResponseSizeInTokens": 1000,
    "addUserTurnTemplate": true
  },
  {
    "title": "Generating First Wiki Search Query",
    "agentName": "Query Generating Agent Three",
    "systemPrompt": "When given a research topic and a breakdown of what search query should be generated, please respond with the specific search query only",
    "prompt": "The conversation topic is:\n\n<conversation_topic>\n{agent1Input}\n</conversation_topic>\n\nAn LLM has carefully broken down what query should be generated to search Wikipedia. The query can be found below:\n\n<llm_research_proposal>\n{agent2Output}\n</llm_research_proposal>\n\nPlease carefully consider the information, and generate a query, which will be sent verbatim to Wikipedia. If a query is supplied in the proposal, use the EXACT query proposed, without any additions or subtractions.\n\nPlease respond ONLY with the query.",
    "lastMessagesToSendInsteadOfPrompt": 5,
    "endpointName": "General-Rag-Fast-Endpoint",
    "preset": "Worker_Preset",
    "maxResponseSizeInTokens": 300,
    "addUserTurnTemplate": true
  }
]