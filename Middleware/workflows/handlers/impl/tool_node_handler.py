# /Middleware/workflows/handlers/impl/tool_node_handler.py
import logging
import traceback
from copy import deepcopy
from typing import Dict, Any, List

from Middleware.workflows.tools.dynamic_module_loader import run_dynamic_module
from Middleware.workflows.handlers.base.base_workflow_node_handler import BaseHandler
from Middleware.workflows.tools.offline_wikipedia_api_tool import OfflineWikiApiClient
from Middleware.workflows.tools.slow_but_quality_rag_tool import SlowButQualityRAGTool

logger = logging.getLogger(__name__)


class ToolNodeHandler(BaseHandler):
    """
    Handles the execution of nodes that call external tools or scripts.

    This handler acts as a router for various tool-based node types,
    dispatching tasks such as running a dynamic Python module, querying a
    local Wikipedia database, or performing RAG and keyword searches.
    """

    def __init__(self, **kwargs):
        """
        Initializes the ToolNodeHandler.

        This method sets up the handler by instantiating the necessary tool
        services that will be used by the various `handle_*` methods.

        Args:
            **kwargs: Arbitrary keyword arguments passed to the parent `BaseHandler`
                      constructor, typically containing shared services.
        """
        super().__init__(**kwargs)
        self.slow_but_quality_rag_service = SlowButQualityRAGTool()
        self.offline_wiki_api_client = OfflineWikiApiClient()

    def handle(self, config: Dict, messages: List[Dict], request_id: str, workflow_id: str,
               discussion_id: str, agent_outputs: Dict, stream: bool) -> Any:
        """
        Routes the request to the correct tool-handling method based on node type.

        This method acts as a dispatcher, reading the 'type' from the node's
        configuration and invoking the corresponding internal method to execute the
        tool's logic. It is the main entry point for the ToolNodeHandler.

        Args:
            config (Dict[str, Any]): The configuration specific to this tool node from the workflow JSON.
            messages (List[Dict[str, str]]): The history of the conversation as a list of role/content pairs.
            request_id (str): The unique identifier for the current API request.
            workflow_id (str): The identifier for the currently executing workflow.
            discussion_id (str): The identifier for the conversation, used for memory lookups.
            agent_outputs (Dict[str, Any]): A dictionary of outputs from preceding nodes, used for variable substitution.
            stream (bool): Indicates if the response should be streamed. Not used by most tools.

        Returns:
            Any: The output generated by the executed tool. The data type varies
                 based on the tool's implementation.

        Raises:
            ValueError: If the 'type' specified in the node config is not a recognized tool type.
        """
        node_type = config.get("type")
        logger.debug(f"Handling tool node of type: {node_type}")

        # The handle signature must match the base handler contract.
        # Internal methods are only passed the parameters they require.
        if node_type == "PythonModule":
            return self.handle_python_module(config, messages, agent_outputs)
        if node_type in ["OfflineWikiApiFullArticle", "OfflineWikiApiBestFullArticle", "OfflineWikiApiTopNFullArticles",
                         "OfflineWikiApiPartialArticle"]:
            return self.handle_offline_wiki_node(config, messages, agent_outputs)
        if node_type in ["ConversationalKeywordSearchPerformerTool", "MemoryKeywordSearchPerformerTool"]:
            # This specific tool needs the discussion_id, so we pass it along.
            return self.perform_keyword_search(config, messages, discussion_id, agent_outputs,
                                               config.get("lookbackStartTurn", 0))
        if node_type == "SlowButQualityRAG":
            return self.perform_slow_but_quality_rag(config, messages, agent_outputs)

        raise ValueError(f"Unknown tool node type: {node_type}")

    def perform_slow_but_quality_rag(self, config, messages, agent_outputs):
        """
        Executes the Slow But Quality Retrieval-Augmented Generation (RAG) process.

        This method applies variables to the system prompt, user prompt, and RAG
        target from the node configuration. It then invokes the RAG service to
        perform analysis on the specified target content.

        Args:
            config (Dict[str, Any]): The configuration for the RAG node, containing prompts and a 'ragTarget'.
            messages (List[Dict[str, str]]): The current conversation history.
            agent_outputs (Dict[str, Any]): A dictionary of outputs from preceding nodes for variable substitution.

        Returns:
            Any: The result from the RAG service. If 'ragTarget' or 'ragType' is
                 missing from the config, it returns an Exception object instead of raising.
        """
        if "ragTarget" not in config:
            return Exception("No rag target specified in Slow But Quality RAG node")
        rag_target = config["ragTarget"]

        if "ragType" not in config:
            return Exception("No rag type specified in Slow But Quality RAG node")
        rag_type = config["ragType"]

        prompt = self.workflow_variable_service.apply_variables(
            config["prompt"], self.llm_handler, messages, agent_outputs, config=config
        )
        system_prompt = self.workflow_variable_service.apply_variables(
            config["systemPrompt"], self.llm_handler, messages, agent_outputs, config=config
        )
        rag_target = self.workflow_variable_service.apply_variables(
            rag_target, self.llm_handler, messages, agent_outputs, config=config
        )
        return self.slow_but_quality_rag_service.perform_rag_on_conversation_chunk(
            system_prompt, prompt, rag_target, config
        )

    def perform_keyword_search(self, config, messages, discussion_id, agent_outputs, lookbackStartTurn=0):
        """
        Performs a keyword search on conversation history or long-term memory.

        This method extracts keywords from the node configuration, applies variables,
        and uses the underlying search tool to find matches within a specified target
        (e.g., 'CurrentConversation' or 'Memory').

        Args:
            config (Dict[str, Any]): The node configuration, containing 'keywords' and an optional 'searchTarget'.
            messages (List[Dict[str, str]]): The current conversation history.
            discussion_id (str): The identifier for the conversation, required for memory lookups.
            agent_outputs (Dict[str, Any]): A dictionary of outputs from preceding nodes for variable substitution.
            lookbackStartTurn (int): The turn from which to start the search, defaulting to 0.

        Returns:
            Any: The result from the keyword search service. If 'keywords' is
                 missing from the config, it returns an Exception object instead of raising.
        """
        if "keywords" not in config:
            return Exception("No keywords specified in Keyword Search node")
        keywords = config["keywords"]

        keywords = self.workflow_variable_service.apply_variables(
            keywords, self.llm_handler, messages, agent_outputs, config=config
        )

        search_target = config.get("searchTarget", "CurrentConversation")
        return self.slow_but_quality_rag_service.perform_keyword_search(
            keywords, search_target, messages=messages, lookbackStartTurn=lookbackStartTurn,
            llm_handler=self.llm_handler, discussion_id=discussion_id
        )

    def handle_python_module(self, config, messages, agent_outputs):
        """
        Dynamically loads and executes a function from an external Python module.

        This method reads a module path, arguments ('args'), and keyword arguments
        ('kwargs') from the node configuration. It applies variables to the
        arguments and then calls the `run_dynamic_module` utility to execute the
        'Invoke' function within the specified module.

        Args:
            config (Dict[str, Any]): The node configuration, requiring 'module_path' and optionally 'args'/'kwargs'.
            messages (List[Dict[str, str]]): The current conversation history, used for variable substitution.
            agent_outputs (Dict[str, Any]): A dictionary of outputs from preceding nodes, used for variable substitution.

        Returns:
            Any: The result returned by the 'Invoke' function of the target module.

        Raises:
            ValueError: If 'module_path' is not specified in the node configuration.
            Exception: Propagates any exception that occurs during variable application on the arguments.
        """
        if "module_path" not in config:
            raise ValueError("No 'module_path' specified for PythonModule node.")
        module_path = config["module_path"]

        args = list(config.get("args", ()))
        kwargs = config.get("kwargs", {})
        message_copy = deepcopy(messages)

        for i, arg in enumerate(args):
            try:
                args[i] = self.workflow_variable_service.apply_variables(
                    str(arg), self.llm_handler, message_copy, agent_outputs, config=config
                )
            except Exception as e:
                logger.error(f"Arg could not have variable applied. Exception: {e}")
                traceback.print_exc()
                raise

        for key, value in kwargs.items():
            kwargs[key] = self.workflow_variable_service.apply_variables(
                str(value), self.llm_handler, message_copy, agent_outputs, config=config
            )

        return run_dynamic_module(module_path, *tuple(args), **kwargs)

    def handle_offline_wiki_node(self, config, messages, agent_outputs):
        """
        Queries an offline Wikipedia database using a search prompt.

        This method extracts a search prompt from the node configuration, applies
        variables to it, and calls the appropriate method on the
        `OfflineWikiApiClient` based on the node's 'type'. It supports queries for
        full articles, summaries, and top N results.

        Args:
            config (Dict[str, Any]): The node configuration, requiring 'promptToSearch' and 'type'.
            messages (List[Dict[str, str]]): The current conversation history, used for variable substitution.
            agent_outputs (Dict[str, Any]): A dictionary of outputs from preceding nodes, used for variable substitution.

        Returns:
            str: The content of the retrieved Wikipedia article(s), or a fallback
                 message if no information is found or an error occurs during the query.

        Raises:
            ValueError: If 'promptToSearch' is not specified in the node configuration.
        """
        if "promptToSearch" not in config:
            raise ValueError("No 'promptToSearch' specified for OfflineWikiApi node.")
        prompt = config["promptToSearch"]

        node_type = config.get("type")

        variabled_prompt = self.workflow_variable_service.apply_variables(
            str(prompt), self.llm_handler, deepcopy(messages), agent_outputs
        )

        try:
            if node_type == "OfflineWikiApiBestFullArticle":
                return self.offline_wiki_api_client.get_top_full_wiki_article_by_prompt(variabled_prompt)
            if node_type == "OfflineWikiApiTopNFullArticles":
                return self.offline_wiki_api_client.get_top_n_full_wiki_articles_by_prompt(
                    variabled_prompt,
                    percentile=config.get("percentile", 0.5),
                    num_results=config.get("num_results", 10),
                    top_n_articles=config.get("top_n_articles", 3)
                )
            if node_type == "OfflineWikiApiPartialArticle":
                results = self.offline_wiki_api_client.get_wiki_summary_by_prompt(variabled_prompt)
            else:  # Fallback for "OfflineWikiApiFullArticle" and deprecated types
                results = self.offline_wiki_api_client.get_full_wiki_article_by_prompt(variabled_prompt)

            return results[0] if results else "No additional information provided"
        except Exception as e:
            logger.error(f"Error accessing Wikipedia information: {e}")
            return f"I'm sorry, I couldn't find any Wikipedia information about '{variabled_prompt}'."