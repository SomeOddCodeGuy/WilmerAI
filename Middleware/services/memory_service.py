# Middleware/services/memory_service.py
import logging
from copy import deepcopy
from typing import Dict, List, Tuple, Optional

from Middleware.utilities import text_utils, vector_db_utils
from Middleware.utilities.config_utils import get_discussion_memory_file_path, get_discussion_chat_summary_file_path
from Middleware.utilities.file_utils import read_chunks_with_hashes
from Middleware.utilities.hashing_utils import extract_text_blocks_from_hashed_chunks

logger = logging.getLogger(__name__)


class MemoryService:
    """
    A service class responsible for all business logic related to managing
    and retrieving conversational memory and summaries.
    """

    def search_vector_memories(self, discussion_id: str, keywords: str, limit: int = 5) -> str:
        """
        Searches for memories in the vector database using keywords.

        Args:
            discussion_id (str): The ID of the conversation.
            keywords (str): A string of space-separated keywords for the search.
            limit (int): The maximum number of memories to return.

        Returns:
            str: A string containing the formatted search results, or a message if none were found.
        """
        if not discussion_id:
            return "Cannot search vector memories without a discussionId."

        logger.info(f"Searching vector memories for discussion '{discussion_id}' with keywords: '{keywords}'")

        found_memories = vector_db_utils.search_memories_by_keyword(discussion_id, keywords, limit)

        if not found_memories:
            return "No relevant memories found in the vector database for the given keywords."

        # The `memory_text` for a vector memory is the summary generated by the LLM.
        summaries = [row['memory_text'] for row in found_memories]

        return '\n\n---\n\n'.join(summaries)

    def get_recent_memories(self, messages: List[Dict[str, str]], discussion_id: str, max_turns_to_search=0,
                            max_summary_chunks_from_file=0, lookback_start=0) -> str:
        """
        Retrieves recent memories from chat messages or memory files.

        Args:
            messages (List[Dict[str, str]]): The list of chat messages for stateless mode.
            discussion_id (str): The ID of the discussion for stateful mode.
            max_turns_to_search (int): Max number of turns to look back in stateless mode.
            max_summary_chunks_from_file (int): Max number of memory chunks to get from a file.
            lookback_start (int): Number of messages to skip from the end.

        Returns:
            str: A string of memory chunks joined by '--ChunkBreak--'.
        """
        logger.debug("Entered MemoryService.get_recent_memories")
        if discussion_id is None:
            final_pairs = self._get_recent_chat_messages_up_to_max(max_turns_to_search, messages, lookback_start)
            logger.debug("Recent Memory complete. Total number of pair chunks: {}".format(len(final_pairs)))
            return '--ChunkBreak--'.join(final_pairs)
        else:
            filepath = get_discussion_memory_file_path(discussion_id)
            hashed_chunks = read_chunks_with_hashes(filepath)
            if not hashed_chunks:
                return "No memories have been generated yet"

            chunks = extract_text_blocks_from_hashed_chunks(hashed_chunks)
            if max_summary_chunks_from_file == -1:
                return '--ChunkBreak--'.join(chunks)

            # Simplified logic: Use provided value or default to 3. Slice handles shorter lists.
            max_chunks = max_summary_chunks_from_file or 3
            return '--ChunkBreak--'.join(chunks[-max_chunks:])

    def get_latest_memory_chunks_with_hashes_since_last_summary(self, discussion_id: str) -> List[Tuple[str, str]]:
        """
        Retrieves memory chunks and hashes since the last summary was created.

        Args:
            discussion_id (str): The ID of the discussion.

        Returns:
            List[Tuple[str, str]]: A list of (text, hash) tuples for new memory chunks.
        """
        memory_filepath = get_discussion_memory_file_path(discussion_id)
        all_memory_chunks = read_chunks_with_hashes(memory_filepath)
        if not all_memory_chunks:
            return []

        summary_filepath = get_discussion_chat_summary_file_path(discussion_id)
        summary_chunks = read_chunks_with_hashes(summary_filepath)
        if summary_chunks:
            last_used_index_from_end = self.find_how_many_new_memories_since_last_summary(summary_chunks,
                                                                                          all_memory_chunks)
            if last_used_index_from_end is not None and last_used_index_from_end != -1:
                actual_index = len(all_memory_chunks) - last_used_index_from_end
                if actual_index == len(all_memory_chunks):
                    return []
                return all_memory_chunks[actual_index:]

        return all_memory_chunks

    def get_chat_summary_memories(self, messages: List[Dict[str, str]], discussion_id: str,
                                  max_turns_to_search=0) -> str:
        """
        Gathers new memories that need to be incorporated into a long-term chat summary.

        Args:
            messages (List[Dict[str, str]]): The chat messages for stateless mode.
            discussion_id (str): The ID of the discussion for stateful mode.
            max_turns_to_search (int): Max number of turns to look back in stateless mode.

        Returns:
            str: A string of new memory chunks to be summarized, joined by newlines.
        """
        if discussion_id is None:
            final_pairs = self._get_recent_chat_messages_up_to_max(max_turns_to_search, messages)
            return '\n------------\n'.join(final_pairs)

        memory_chunks_with_hashes = self.get_latest_memory_chunks_with_hashes_since_last_summary(discussion_id)
        if not memory_chunks_with_hashes:
            return ''

        memory_chunks = [text_block for text_block, _ in memory_chunks_with_hashes]
        return '\n------------\n'.join(memory_chunks)

    def _get_recent_chat_messages_up_to_max(self, max_turns_to_search: int, messages: List[Dict[str, str]],
                                            lookback_start: int = 0) -> List[str]:
        """
        Internal helper to get recent chat messages up to a maximum number of turns.

        Args:
            max_turns_to_search (int): The maximum number of turns to retrieve.
            messages (List[Dict[str, str]]): The full list of chat messages.
            lookback_start (int): Number of messages to skip from the end.

        Returns:
            List[str]: A list of formatted message chunks.
        """
        if len(messages) <= 1 or lookback_start >= len(messages):
            return ["There are no memories to grab yet"]

        message_copy = deepcopy(messages)
        start_index = len(message_copy) - lookback_start
        end_index = max(0, start_index - max_turns_to_search)
        selected_messages = message_copy[end_index:start_index]

        if not selected_messages:
            return ["There are no memories to grab yet"]

        pair_chunks = text_utils.get_message_chunks(selected_messages, 0, 400)
        filtered_chunks = [s for s in pair_chunks if s]
        return text_utils.clear_out_user_assistant_from_chunks(filtered_chunks)

    def get_current_summary(self, discussion_id: str) -> str:
        """
        Retrieves the most recent full summary text from its file.

        Args:
            discussion_id (str): The ID of the discussion.

        Returns:
            str: The text of the most recent chat summary.
        """
        filepath = get_discussion_chat_summary_file_path(discussion_id)
        current_summary_chunks = read_chunks_with_hashes(filepath)

        if not current_summary_chunks:
            return "There is not yet a summary file"

        return extract_text_blocks_from_hashed_chunks(current_summary_chunks)[0]

    def get_current_memories(self, discussion_id: str) -> List[str]:
        """
        Retrieves all current memory chunk texts from their file.

        Args:
            discussion_id (str): The ID of the discussion.

        Returns:
            List[str]: A list containing all memory chunk texts.
        """
        filepath = get_discussion_memory_file_path(discussion_id)
        current_memory_chunks = read_chunks_with_hashes(filepath)

        if not current_memory_chunks:
            return ["There are not yet any memories"]

        return extract_text_blocks_from_hashed_chunks(current_memory_chunks)

    def find_how_many_new_memories_since_last_summary(self, hashed_summary_chunk: Optional[List[Tuple[str, str]]],
                                                      hashed_memory_chunks: List[Tuple[str, str]]) -> int:
        """
        Finds the number of new memories created since the last summary.

        Args:
            hashed_summary_chunk (Optional[List[Tuple[str, str]]]): The hashed chunks from the summary file.
            hashed_memory_chunks (List[Tuple[str, str]]): The hashed chunks from the memory file.

        Returns:
            int: The number of new memories, or -1 if no match is found.
        """
        if not hashed_memory_chunks:
            return -1
        if not hashed_summary_chunk:
            return len(hashed_memory_chunks)

        summary_hash = hashed_summary_chunk[-1][1]
        memory_hashes = [hash_tuple[1] for hash_tuple in hashed_memory_chunks]

        try:
            return memory_hashes[::-1].index(summary_hash)
        except ValueError:
            return -1
